{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = np.array([[5, 3, 0, 2, 1], [4, 0, 0, 2, 1], [1, 3, 1, 0, 5], [1, 0, 2, 0, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned User Matrix:\n",
      "[[ 5.43202282 -2.91659222 -0.93896115 -0.32399058]\n",
      " [ 3.60310831 -2.38145478  1.47881379  0.39924103]\n",
      " [ 4.99132244  3.11531436 -1.13793608  0.29430966]\n",
      " [ 3.34336945  2.65423747  1.63067173 -0.34324022]]\n",
      "Learned Item Matrix:\n",
      "[[ 0.63510826  0.39793542  0.14861237  0.22995808  0.60275911]\n",
      " [-0.59296528  0.01927595  0.27236776 -0.34260524  0.67561681]\n",
      " [ 0.24395563 -0.88724353  0.30237083  0.15374882  0.19549361]\n",
      " [-0.15341309 -0.18993951 -0.83655012  0.32103755  0.37081828]]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "U, S, Vh = scipy.linalg.svd(user_item_matrix, full_matrices=False)\n",
    "\n",
    "user_matrix = np.dot(U, np.diag(S))\n",
    "\n",
    "item_matrix = Vh\n",
    "\n",
    "# Print the learned user and item matrices\n",
    "print('Learned User Matrix:')\n",
    "print(user_matrix)\n",
    "\n",
    "print('Learned Item Matrix:')\n",
    "print(item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.00000000e+00,  3.00000000e+00,  4.85235125e-16,\n",
       "         2.00000000e+00,  1.00000000e+00],\n",
       "       [ 4.00000000e+00,  9.37725527e-17, -1.07408510e-15,\n",
       "         2.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "         4.23722441e-16,  5.00000000e+00],\n",
       "       [ 1.00000000e+00, -1.12161970e-15,  2.00000000e+00,\n",
       "         6.28414357e-16,  4.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_matrix, item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned User Matrix:\n",
      "[[1.50046562e+00 0.00000000e+00 1.45859014e-01 4.58685632e-01\n",
      "  5.75047598e-01 7.99415173e-01]\n",
      " [1.66229226e+00 0.00000000e+00 6.51330590e-06 5.54628919e-06\n",
      "  1.22132381e+00 1.57613648e+00]\n",
      " [6.53666143e-01 1.16314609e+00 2.83316559e+00 0.00000000e+00\n",
      "  5.47326516e-04 0.00000000e+00]\n",
      " [0.00000000e+00 2.32420747e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.10596091e+00 0.00000000e+00]]\n",
      "Learned Item Matrix:\n",
      "[[1.46163786e+00 0.00000000e+00 0.00000000e+00 4.86432760e-03\n",
      "  5.42742565e-01]\n",
      " [3.01702343e-03 0.00000000e+00 8.60260254e-01 0.00000000e+00\n",
      "  1.72105819e+00]\n",
      " [1.43228395e-02 1.05888755e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.33013671e-01]\n",
      " [4.46528407e+00 6.20370796e+00 0.00000000e+00 2.14265152e+00\n",
      "  0.00000000e+00]\n",
      " [8.97830701e-01 0.00000000e+00 2.09317267e-04 7.99341887e-04\n",
      "  0.00000000e+00]\n",
      " [3.00591636e-01 0.00000000e+00 0.00000000e+00 1.26307687e+00\n",
      "  6.20339056e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=6)\n",
    "\n",
    "user_matrix = nmf.fit_transform(user_item_matrix)\n",
    "\n",
    "item_matrix = nmf.components_\n",
    "\n",
    "# Print the learned user and item matrices\n",
    "print('Learned User Matrix:')\n",
    "print(user_matrix)\n",
    "\n",
    "print('Learned Item Matrix:')\n",
    "print(item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.99998103e+00, 3.00000000e+00, 1.20367392e-04, 2.00028470e+00,\n",
       "        1.00004586e+00],\n",
       "       [4.00000962e+00, 4.13044169e-05, 2.55644163e-04, 1.99985560e+00,\n",
       "        9.99976741e-01],\n",
       "       [1.00000281e+00, 3.00000377e+00, 1.00060846e+00, 3.18008376e-03,\n",
       "        4.99999676e+00],\n",
       "       [9.99977850e-01, 0.00000000e+00, 1.99965480e+00, 8.84040883e-04,\n",
       "        4.00009629e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_matrix, item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 4.876967451629531\n",
      "Iteration 100, Loss: 1.755121429415912\n",
      "Iteration 200, Loss: 1.751467938862448\n",
      "Iteration 300, Loss: 1.746634235632274\n",
      "Iteration 400, Loss: 1.7429525416012415\n",
      "Iteration 500, Loss: 1.7410169355743486\n",
      "Iteration 600, Loss: 1.7400430058447651\n",
      "Iteration 700, Loss: 1.7395436963721427\n",
      "Iteration 800, Loss: 1.7392787589967538\n",
      "Iteration 900, Loss: 1.7391325807219917\n",
      "Learned User Matrix:\n",
      "[[ 0.67479719  1.22182937  0.54187496  0.84939027 -0.08366531  1.51050801]\n",
      " [ 1.15663578  1.25573014  0.47612732 -0.1482253   0.47401612  0.22807891]\n",
      " [-0.55181591  0.08820665  1.27951717  1.5644909   0.81352377 -0.00179925]\n",
      " [ 0.39076422 -0.46849813  0.74162703  0.33175222  1.59962412 -0.00167432]]\n",
      "Learned Item Matrix:\n",
      "[[ 1.27600512 -0.50489691  0.17073203  0.59536369 -0.07165627]\n",
      " [ 1.42842279  0.39246052 -0.56763311  0.86721117 -0.08949339]\n",
      " [ 0.59327134  0.59266464  0.20284271  0.18480065  1.38485241]\n",
      " [ 0.33846081  1.35459745  0.12831997 -0.00787138  1.17250867]\n",
      " [ 0.37627993 -0.2983055   0.87248739  0.03375536  1.57608773]\n",
      " [ 1.15693102  0.86109793  0.27059465  0.28905289 -0.28718848]]\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = user_item_matrix.shape\n",
    "\n",
    "# Set the number of latent features (factors)\n",
    "num_factors = 6\n",
    "\n",
    "# Set the learning rate and regularization parameter\n",
    "learning_rate = 0.01\n",
    "regularization = 0.1\n",
    "\n",
    "# Initialize user and item matrices with random values\n",
    "user_matrix = np.random.random((num_users, num_factors))\n",
    "item_matrix = np.random.random((num_factors, num_items))\n",
    "\n",
    "# Define the loss function (Mean Squared Error)\n",
    "def loss(user_matrix, item_matrix, user_item_matrix, regularization):\n",
    "    predicted_ratings = np.dot(user_matrix, item_matrix)\n",
    "    mse = np.sum((user_item_matrix - predicted_ratings) ** 2) / np.sum(user_item_matrix != 0)\n",
    "    reg_term = 0.5 * regularization * (np.sum(user_matrix ** 2) + np.sum(item_matrix ** 2))\n",
    "    total_loss = mse + reg_term\n",
    "    return total_loss\n",
    "\n",
    "# Perform gradient descent to minimize the loss\n",
    "num_iterations = 1000\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Compute predicted ratings and error\n",
    "    predicted_ratings = np.dot(user_matrix, item_matrix)\n",
    "    error = user_item_matrix - predicted_ratings\n",
    "\n",
    "    # Update user and item matrices using gradient descent\n",
    "    user_matrix -= learning_rate * (-2 * np.dot(error, item_matrix.T) + 2 * regularization * user_matrix)\n",
    "    item_matrix -= learning_rate * (-2 * np.dot(user_matrix.T, error) + 2 * regularization * item_matrix)\n",
    "\n",
    "    # Compute and print the loss\n",
    "    current_loss = loss(user_matrix, item_matrix, user_item_matrix, regularization)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i}, Loss: {current_loss}')\n",
    "\n",
    "# Print the learned user and item matrices\n",
    "print('Learned User Matrix:')\n",
    "print(user_matrix)\n",
    "\n",
    "print('Learned Item Matrix:')\n",
    "print(item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.93136980e+00,  2.93620193e+00, -2.36937131e-02,\n",
       "         1.98857934e+00,  1.02297084e+00],\n",
       "       [ 3.94412530e+00,  4.52375504e-02,  3.75294905e-02,\n",
       "         1.94868498e+00,  9.71900221e-01],\n",
       "       [ 1.01452726e+00,  2.94657978e+00,  1.02531686e+00,\n",
       "        -9.55761203e-04,  4.92067028e+00],\n",
       "       [ 9.81644315e-01,  2.91457346e-02,  1.92085391e+00,\n",
       "         1.43137412e-02,  3.95158190e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_matrix, item_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
